model:
  - GraphNTL
trainer:
  - NTL
device:
  - cuda
batch_size:
  - 128
learning_rate:
  - 0.001
training_epochs:
  - 500
hidden_dim:
  - 32
num_trans:
  - 6
num_layers:
  - 4
norm_layer:
  - gn
bias:
  - False
loss:
  - EucDCL
loss_temp:
  - 2
l2:
  - 0.0001
aggregation:
  - add
optimizer:
  - Adam
scheduler:
  -
    class: StepLR
    args:
      step_size: 100
      gamma: 0.5
early_stopper:
  -
    class: Patience
    args:
      patience: 100
      use_train_loss: False

shuffle:
  - True
num_repeat:
  - 1
result_folder:
  - RESULTS/RESULTS_