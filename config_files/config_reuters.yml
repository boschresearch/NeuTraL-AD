model:
  - textNTL
trainer:
  - NTL
network:
  - textNTL
device:
  - cuda
batch_size:
  - 128
learning_rate:
  - 0.0005
training_epochs:
  - 50
latent_dim:
  - 300
enc_hdim:
  - 100
num_trans:
  - 10
trans_nlayers:
  - 3
trans_hdim:
  - 300
trans_type:
  - mul
pretrained_model:
  - GloVe_6B
loss:
  - DCL
enc_bias:
  - False
loss_temp:
  - 0.1
l2:
  - 0.00001
optimizer:
  - Adam
scheduler:
  -
    class: StepLR
    args:
      step_size: 50
      gamma: 0.5
early_stopper:
  -
    class: Patience
    args:
      patience: 50
      use_train_loss: True

shuffle:
  - True
num_repeat:
  - 1
result_folder:
  - RESULTS/RESULTS_